# -*- coding: utf-8 -*-
"""「「tx_futuresipynb月合約k圖 」階段 gspread 」修訂中v01_1140124」

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bOCWDseXWD19jQFVSFgJlEa3OhLjWs1K
"""

#!pip install finmind

from FinMind.data import DataLoader

dl = DataLoader()

future_data = dl.taiwan_futures_daily(futures_id='TX', start_date='2022-12-15')

"""# 1. Download row data"""

#future_data= future_data[(future_data.contract_date=="202411")]
future_data = future_data[(future_data.trading_session == "position")]
future_data = future_data[future_data['contract_date'].str.len() <= 6]
#future_data = future_data[(future_data.settlement_price > 0)]
future_data = future_data[future_data['contract_date'] == future_data.groupby('date')['contract_date'].transform('min')] #近月

df = future_data.drop_duplicates(subset=['date'])
df

"""2. Extract data for every Wednsday"""

import calendar
import pandas as pd
import logging

# ... (logging setup from previous response) ...

# Convert the 'date' column to datetime objects
future_data['date'] = pd.to_datetime(future_data['date'])
df['date'] = pd.to_datetime(df['date'])  # Ensure df['date'] is datetime

# Filter for all Wednesdays and handle exceptions
wednesdays_data = []
matched_dates = set()  # Keep track of already matched dates

# Get the year range from df
min_year = df['date'].min().year
max_year = df['date'].max().year

for year in range(min_year, max_year + 1):
    for month in range(1, 13):
        cal = calendar.monthcalendar(year, month)
        for week in cal:
            if week[calendar.WEDNESDAY]:
                try:
                    target_date = pd.to_datetime(f"{year}-{month:02d}-{week[calendar.WEDNESDAY]:02d}")

                    # Find the closest matching date in df
                    while target_date not in df['date'].values and target_date <= df['date'].max():
                        target_date += pd.Timedelta(days=1)

                    # Check if a match was found and the date hasn't been used before
                    if target_date in df['date'].values and target_date not in matched_dates:
                        matching_row = df[df['date'] == target_date].iloc[0]
                        wednesdays_data.append(matching_row)
                        matched_dates.add(target_date)  # Add to matched dates

                except OutOfBoundsDatetime as e:
                    logging.exception(f"OutOfBoundsDatetime error for target_date: {target_date}")
                    break

wednesdays_data = pd.DataFrame(wednesdays_data)
wednesdays_data['contract_status'] = "contract close"

# Print or use wednesdays_data as needed
wednesdays_data



"""3.Extract data for the next day of each Wednsday"""

# Second extraction based on dates from wednesdays_data + 1 day
extracted_data = []
matched_dates_extracted = set()  # Keep track of matched dates for this extraction

for index, row in wednesdays_data.iterrows():
    target_date = row['date'] + pd.Timedelta(days=1)  # Target date for second extraction

    # Find the closest matching date in df, similar to wednesdays_data logic
    while target_date not in df['date'].values and target_date <= df['date'].max():
        target_date += pd.Timedelta(days=1)

    # Check if a match was found and the date hasn't been used before
    if target_date in df['date'].values and target_date not in matched_dates_extracted:
        matching_row = df[df['date'] == target_date].iloc[0]  # Extract from df
        extracted_data.append(matching_row)
        matched_dates_extracted.add(target_date)

extracted_data = pd.DataFrame(extracted_data)
extracted_data['contract_status'] = "contract open"

extracted_data

"""4. Combination of these two extracted data to be Open and Close Date of each week contract"""

# Combine and sort the DataFrames
combined_data = pd.concat([wednesdays_data, extracted_data], ignore_index=True)
combined_data = combined_data.sort_values(by=['date'])  # Sort by 'date'

combined_data

"""5. Refit the combined data to new build dataframe gethering serial order"""

# Create a list of dictionaries, each representing a row
data_list = [row.to_dict() for index, row in combined_data.iterrows()]

# Create the new DataFrame from the list of dictionaries
new_combined_data = pd.DataFrame(data_list)

# Remove the first row
new_combined_data = new_combined_data.iloc[1:].copy()

new_combined_data

"""6. Build a new dataframe with  title of each weekly contracts and fill primarily open dates from new_bimbined_data"""

# Create the new DataFrame
new_df = pd.DataFrame(columns=["開倉日期", "商品名稱", "合約名稱", "開盤", "最高", "最低", "收盤"])

# Extract data for "開倉日期" and "合約名稱"
open_contract_data = combined_data[combined_data['contract_status'] == "contract open"]
new_df["開倉日期"] = open_contract_data["date"]

new_df["商品名稱"] = open_contract_data["futures_id"]
new_df["合約名稱"] = open_contract_data["contract_date"]


new_df

""" 7. Fill extracted data from df raw dataframe ( loop with range between open and close date) in.
   
   The current week contract which is not yet closed would go through extracting data from the lastest date of df raw dataframe.
"""

import pandas as pd

# Assuming you have 'new_combined_data', 'df', and 'new_df' DataFrames


# 1. Get close date for each open date in new_df
new_df['收盤日期'] = pd.NaT  # Initialize a new column for close dates

for index, row in new_df.iterrows():
    open_date = row['開倉日期']

    try:
        open_date_index = new_combined_data[new_combined_data['date'] == open_date].index[0]  # Use new_combined_data

        if open_date_index + 1 < len(new_combined_data):
            close_date = new_combined_data.loc[open_date_index + 1, 'date']
            new_df.loc[index, '收盤日期'] = close_date
        else:
            # If close date is missing, use the last date in df
            close_date = df['date'].max()  # Get the last date in df
            new_df.loc[index, '收盤日期'] = close_date
            print(f"Warning: No close date found for open date {open_date}. Using last date in df: {close_date}")

    except IndexError:
        print(f"Warning: No close date found for open date {open_date} (not found)")

# 2-6. Extract values from df based on open and close dates
# ... (Rest of your code remains the same) ...


# 2-6. Extract values from df based on open and close dates
for index, row in new_df.iterrows():
    open_date = row['開倉日期']
    close_date = row['收盤日期']

    # Filter df based on open and close dates
    filtered_df = df[(df['date'] >= open_date) & (df['date'] <= close_date)]

    # Extract values and assign to new_df
    try:
        new_df.loc[index, '最高'] = filtered_df['max'].max()
        new_df.loc[index, '最低'] = filtered_df['min'].min()
        new_df.loc[index, '開盤'] = filtered_df['open'].iloc[0]
        new_df.loc[index, '收盤'] = filtered_df['close'].iloc[-1]
    except IndexError:
        # Add a placeholder or handling logic for IndexError
        print(f"Warning: IndexError encountered for open_date: {open_date}, close_date: {close_date}")
        # You can assign default values, skip the row, or raise a custom exception
        # For example, to assign NaN values:
        # new_df.loc[index, ['最高', '最低', '開盤', '收盤']] = float('nan')
#display(new_df)

""" 8. Build a Monthly contract table named new_df_Mth"""

import pandas as pd

# Assuming you have the 'new_df' DataFrame

# Group by '合約名稱' and get the first order of each group
grouped = new_df.groupby('合約名稱')
new_df_Mth = grouped.first()[['開倉日期', '商品名稱', '開盤']]
new_df_Mth = new_df_Mth.reset_index()  # Reset index to make '合約名稱' a column


# Reorder and rename columns
new_df_Mth = new_df_Mth[['開倉日期', '商品名稱', '合約名稱', '開盤']]
# Add missing columns and fill with NaN
new_df_Mth['最高'] = float('nan')
new_df_Mth['最低'] = float('nan')
new_df_Mth['收盤'] = float('nan')
# Initialize '收盤日期' with object dtype to avoid the warning
new_df_Mth['收盤日期'] = pd.Series(dtype=object) # or  = float('nan')


# Fill '最高' column in new_df_Mth with max value from new_df
for contract_name in new_df_Mth['合約名稱'].unique():
    max_value = new_df.loc[new_df['合約名稱'] == contract_name, '最高'].max()
    new_df_Mth.loc[new_df_Mth['合約名稱'] == contract_name, '最高'] = max_value

# Fill '最低' column in new_df_Mth with min value from new_df
for contract_name in new_df_Mth['合約名稱'].unique():
    min_value = new_df.loc[new_df['合約名稱'] == contract_name, '最低'].min()
    new_df_Mth.loc[new_df_Mth['合約名稱'] == contract_name, '最低'] = min_value


# Fill '收盤' column in new_df_Mth with the last order's '收盤' value from new_df
for contract_name in new_df_Mth['合約名稱'].unique():
    last_order_value = new_df.loc[new_df['合約名稱'] == contract_name, '收盤'].iloc[-1]
    new_df_Mth.loc[new_df_Mth['合約名稱'] == contract_name, '收盤'] = last_order_value

# Fill '收盤日期' column in new_df_Mth with the last order's '收盤日期' value from new_df
for contract_name in new_df_Mth['合約名稱'].unique():
    last_order_date = new_df.loc[new_df['合約名稱'] == contract_name, '收盤日期'].iloc[-1]
    # Convert last_order_date to string before assigning
    new_df_Mth.loc[new_df_Mth['合約名稱'] == contract_name, '收盤日期'] = str(last_order_date)[:10] # Keep only the date part

# Convert '收盤日期' to the desired format
# new_df_Mth['收盤日期'] = pd.to_datetime(new_df_Mth['收盤日期']).dt.strftime('%Y-%m-%d') # No longer needed as we already have the correct format

# Display the new DataFrame
#display(new_df_Mth)

# Add new columns to new_df_Mth
new_df_Mth['span'] = 0  # Initialize with 0
new_df_Mth['cost'] = 0   # Initialize with 0
new_df_Mth['20周均震幅'] = 0  # Initialize with 0
new_df_Mth['最小震幅'] = 0  # Initialize with 0
new_df_Mth['小震幅'] = 0   # Initialize with 0
new_df_Mth['平均震幅'] = 0  # Initialize with 0
new_df_Mth['大震幅'] = 0   # Initialize with 0
new_df_Mth['最大震幅'] = 0  # Initialize with 0

# ... (Rest of your code, including the loop to extract values) ...

# Calculate values for the new columns after extracting data from df
for index, row in new_df_Mth.iterrows():
    new_df_Mth.loc[index, 'span'] = row['收盤'] - row['開盤']  # Calculate span

new_df_Mth.head()

# Calculate values for the new columns after extracting data from df
for index, row in new_df_Mth.iterrows():
    new_df_Mth.loc[index, 'span'] = row['最高'] - row['最低']  # Calculate span
    new_df_Mth.loc[index, 'cost'] = (row['最高'] + row['最低']) / 2  # Calculate cost

# Calculate 20DailySpanMa (rolling mean of 'span' over 20 rows)
new_df_Mth['20周均震幅'] = new_df_Mth['span'].rolling(window=20, min_periods=0).mean().astype(int)

# Calculate other columns based on rolling calculations
new_df_Mth['最小震幅'] = new_df_Mth['span'].rolling(window=20, min_periods=0).min()
new_df_Mth['最大震幅'] = new_df_Mth['span'].rolling(window=20, min_periods=0).max()
new_df_Mth['平均震幅'] = new_df_Mth['20周均震幅']
new_df_Mth['小震幅'] = (new_df_Mth['最小震幅'] + new_df_Mth['平均震幅']) / 2
new_df_Mth['大震幅'] = (new_df_Mth['最大震幅'] + new_df_Mth['平均震幅']) / 2
new_df_Mth2=new_df_Mth
new_df_Mth2

"""Transfer dataframe to google sheet"""

# Install necessary libraries
#!pip install --upgrade gspread pandas gspread_dataframe

"""API key.json store in drive and shareed for downloading to Colad VM temperially by url, which doesn't go through drive authentication.Download key to content temperially."""

import requests

# Direct download link
url = "https://drive.google.com/uc?id=1PUo8axrWc0zOjTHE0f4zsRweVNGCcq6z&export=download"

# Download the file
response = requests.get(url)
if response.status_code == 200:
    with open("mtx-spreads-analysis-179ea8a41891.json", "wb") as file:
        file.write(response.content)
    print("File downloaded successfully.")
else:
    print(f"Failed to download file. HTTP status code: {response.status_code}")

# Path to the downloaded service account file
SERVICE_ACCOUNT_FILE = 'mtx-spreads-analysis-179ea8a41891.json'

"""
1. the gsheet api KEY was permently stored in google drive,/My drive/key
2. the dataset is transferred to the  worksheet,Weekly, of spreadsheet,關卡價"""

import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
from gspread_dataframe import set_with_dataframe

# Authenticate using th
SERVICE_ACCOUNT_FILE = 'mtx-spreads-analysis-179ea8a41891.json' # stored in my drive w/o eliminated as session end
SCOPES = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)

# Initialize the gspread client
client = gspread.authorize(creds)

# Access the Google Sheet
sheet_name = "關卡價"
spreadsheet = client.open(sheet_name)
worksheet = spreadsheet.worksheet("Monthly")

# Clear existing data in the sheet (optional)
worksheet.clear()

# Write the DataFrame to the sheet
set_with_dataframe(worksheet, new_df_Mth2)

"""To trigger GAS web app to write data from monthly to 月 sheet of 關卡價"""

import requests

def trigger_gas_webapp():
    # The URL of the GAS web app
    url = "https://script.google.com/macros/s/AKfycbxFLi4_yhfdsDGnEAYuqrj1aCbx8izUuWjtM-7pyQOnRUToiHfY6-e6FA3yQjKjCl47Cw/exec"

    try:
        # Send a GET request to the GAS web app
        response = requests.get(url)

        # Check the response status code
        if response.status_code == 200:
            print("Request successful!")
            print("Response from GAS:", response.text)
        else:
            print(f"Request failed with status code {response.status_code}")
    except Exception as e:
        print(f"An error occurred: {e}")

if __name__ == "__main__":
    trigger_gas_webapp()

